
# 左值和右值
如果你可以对一个表达式取地址，那这个表达式就是个lvalue。

如果一个表达式的类型是一个lvalue reference (例如, T& 或 const T&, 等.)，那这个表达式就是一个lvalue。

其它情况，这个表达式就是一个rvalue。从概念上来讲(通常实际上也是这样)，rvalue对应于临时对象，例如函数返回值或者通过隐式类型转换得到的对象，大部分字面值(e.g., 10 and 5.3)也是rvalues。

## 引用折叠之本质细节

这个问题的核心是，C++11当中的一些构造会弄出来引用的引用，而C++不允许出现引用的引用。如果代码当中显示的出现了一个引用的引用，那代码就是不合法的:
```cpp
Widget w1;
Widget& & w2 = w1;               // error! No such thing as “reference to reference”
```
但是，有些情况下，在你对类型进行操作的时候可能会搞出来引用的引用，编译器如果对这种情况报错是不对的。我们从C++98/C++03标准的时候就知道这件事了。

在对一个 universal reference 的模板参数进行类型推导时候，同一个类型的 lvalues 和 rvalues 被推导为稍微有些不同的类型。具体来说，类型T的lvalues被推导为T&(i.e., lvalue reference to T)，而类型T的 rvalues 被推导为 T。(注意，虽然 lvalue 会被推导为lvalue reference，但 rvalues 却不会被推导为 rvalue references!) 我们来看下分别用rvalue和lvalue来调用一个接受universal reference的模板函数时会发生什么:

```cpp
template<typename T>
void f(T&& param);

int x;

f(10);                           // invoke f on rvalue
f(x);                            // invoke f on lvalue
```
当用rvalue 10调用 f 的时候, T被推导为 int，实例化的 f 看起来像这样:
```cpp
void f(int&& param);             // f instantiated from rvalue
```
这里一切都OK。但是当我们用lvalue x 来调用 f 的时候，T 被推导为int&，而实例化的 f 就包含了一个引用的引用:
```cpp
void f(int& && param);           // initial instantiation of f with lvalue
```
因为这里出现了引用的引用，这实例化的代码乍一看好像不合法，但是像– “f(x)” –这么写代码是完全合理的。为了避免编译器对这个代码报错，C++11引入了一个叫做“引用折叠”(reference collapsing)的规则来处理某些像模板实例化这种情况下带来的"引用的引用"的问题。

因为有两种类型的引用 (lvalue references 和 rvalue references)，那"引用的引用"就有四种可能的组合: lvalue reference to lvalue reference, lvalue reference to rvalue reference, rvalue reference to lvalue reference, 以及 rvalue reference to rvalue reference。

引用折叠只有两条规则:

一个 rvalue reference to an rvalue reference 会变成 (“折叠为”) 一个 rvalue reference.
所有其他种类的"引用的引用" (i.e., 组合当中含有lvalue reference) 都会折叠为 lvalue reference.

# stl 容器是线程安全的吗
STL不是线程安全的, 所以在每一次插入元素,删除元素,读取元素时,必须保证原子操作. 读取元素也许要原子? 嗯,是的. 因为你得到了一个迭代器后, 这个迭代器对应的容器可能被别的线程修改!

所以(下面来自<<　Effective STL　>> 条款十二):
- 在每次调用容器的成员函数期间都要锁定该容器。
- 在每个容器返回的迭代器（例如通过调用begin或end）的生存期之内都要锁定该容器。
- 在每个在容器上调用的算法执行期间锁定该容器。（这事实上没有意义，因为，正如条款32所解释的，算法没有办法识别出它们正在操作着的容器。不过，我们将在这里检验这个选项，因为它的意义在于看看为什么即使是可能的它也不能工作。）

# adapters

如果一个类（class A）（或是函数等）的成员、功能与另一个类（class B）类似，但是有一些不同之处，可以通过封装class B来实现class A，从而将class B的接口转化为class A 的接口。总而言之，就是把一个已经存在的东西，改成一个我们需要的东西。

- 容器适配器（container adapters）
- 仿函数适配器（function adapters）
- 迭代器适配器（iterator adapters）

，STL给我们的stack、queue（栈和队列）并不是所谓的容器（如vector、list等），而是容器适配器。stack和queue封装其他容器，修饰其接口以满足自身逻辑结构的需求（stack先入后出、queue先入先出）。

💬下面抛出两个问题：

问：所谓STL中的stack和queue封装其他容器，这个其他容器是什么呢？
答：是另外一个线性序列容器，deque

问：为什么要使用deque作为stack和queue的底层容器呢？
答：想要回答这个问题，必须先简单认识deque的结构。

deque的迭代器

deque不是真正意义上的连续空间，而是分段式的空间，为了营造出整体连续的假象，满足随机访问的需求，STL为deque设计出一个复杂的迭代器。

🔎 deque的迭代器类包含四个指针，分别是：cur, first, last, node

迭代器中各个指针各司其职，cur负责迭代器的首要工作，访问所指元素，first和last则在告诉迭代器访问的范围，当使用迭代器对deque做遍历操作时，只要迭代器指向还没脱离当前缓冲区，就支持随机访问，而当迭代器的cur和last指针相同时，若要继续访问下一个元素，则要跳到下一个缓冲区，恰好node就会帮我们找到下一个（或上一个）缓冲区。

deque的缺点

- 随机访问效率低。虽然deque支持随机访问，但是其效率远没有vector、array的效率高。因为其分段式的结构，使其在跨越不同缓冲区的时候会消耗时间，从而降低效率。
- 不适合遍历。受其结构特性影响，对deque遍历时，需要频繁检测迭代器是否到达某个缓冲区的边界，导致效率低下。

deque的优点
- 相比vector，deque减少了空间浪费，按需开辟空间。在数据量较少的情况下，deque的数据都集中在某几个缓冲区，此时可以基本忽略其缺点（随机访问效率低、不适合遍历），性能优于vector。而且，deque的头删、头插的效率也远高于vector，因为它不用挪动数据，最多只需再开一块空间。
- 相比list，deque支持随机访问。并且其底层是连续空间，空间利用率比较高，不需要存储额外字段

🔎为什么要使用deque作为stack和queue的底层容器呢？

stack和queue都是特殊的线性数据结构，只在端口处访问数据，stack先进先出，queue先进后出。都不支持遍历和随机读取，所以deque运用于stack和queue中，其缺点并不会体现出来。

而且，deque支持头插尾插、头删尾删（且效率高于vector），提供“整体连续”的空间，提高了空间的使用率（vector有空间冗余问题，list需要存储额外字段）。
所以使用deque作为stack和queue的底层容器可谓是“取其精华、去其糟粕”，规避了deque的缺点，利用了deque的优点。

# 迭代器

迭代器提供了一种统一的方法来访问容器中的元素，而不需要关心容器的具体类型。

迭代器的主要作用包括：

- 遍历容器: 通过迭代器可以遍历容器中的所有元素。例如，使用 begin() 和 end() 方法获取容器的起始和结束迭代器，然后通过循环来访问每个元素。
- 访问元素: 可以通过迭代器读取或修改容器中的元素。
- 连接算法与容器: STL 中的很多算法（如排序、查找等）都是通过迭代器来操作容器的。

C++ STL 中有五种主要的迭代器类型，它们分别是：

输入迭代器（Input Iterators）: 这种迭代器用于从容器中读取数据。它只支持单向遍历，即只能向前移动（通过 ++ 操作符）。输入迭代器只能进行一次读取，读取后迭代器就会前进到下一个元素。

输出迭代器（Output Iterators）: 与输入迭代器相反，输出迭代器用于向容器中写入数据。它同样只支持单向遍历，且只能进行一次写入操作，写入后迭代器会自动前进到下一个位置。

前向迭代器（Forward Iterators）: 前向迭代器类似于输入和输出迭代器，但它支持多次读写操作。它也只能单向遍历，但可以对同一个元素进行多次访问。

双向迭代器（Bidirectional Iterators）: 如其名，双向迭代器可以在容器中向前和向后移动。它扩展了前向迭代器的功能，使得迭代器可以使用 -- 操作符向前移动。双向迭代器在像 list 和 set 这样的容器中非常有用。

随机访问迭代器（Random Access Iterators）: 这是最强大的迭代器类型，它支持所有前面提到的迭代器的功能，并且能够进行随机访问。这意味着除了能够向前和向后移动，随机访问迭代器还能够直接跳跃到任意位置（如通过 + 或 - 操作符）。vector 和 deque 容器提供了随机访问迭代器。

# 算法
STL 算法库大致可以分为以下几类：

非修改性算法（Non-modifying algorithms）: 这类算法不修改容器中的元素。典型的操作包括遍历（for_each）、查找（find、find_if）、计数（count、count_if）、搜索（search）等。

修改性算法（Modifying algorithms）: 这类算法会修改容器中的元素。它们包括对元素进行操作的算法（如 copy、move、replace、fill）、删除操作（如 remove、unique）以及重新排列元素的操作（如 reverse、rotate、shuffle）。

排序和相关操作（Sorting and related operations）: 这些算法用于排序容器中的元素，如 sort、stable_sort、partial_sort。还包括用于在已排序的序列中执行操作的算法，如 binary_search、lower_bound、upper_bound。

数值算法（Numeric algorithms）: 这类算法主要用于数值计算，包括对序列进行数学运算（如 accumulate、inner_product）和生成数值序列（如 iota、adjacent_difference）。

## find()和binary_search()有什么区别？
find() 和 binary_search() 是 C++ STL 中的两种不同的搜索算法，它们的主要区别在于它们的工作原理和使用场景。

find() 函数:

工作原理: find() 是一种线性搜索算法。它从容器的开始位置遍历到结束位置，逐个检查每个元素，直到找到目标元素或遍历完所有元素。

时间复杂度: 因为它是一种线性搜索，所以在最坏的情况下，其时间复杂度是 O(n)，其中 n 是容器中元素的数量。

使用场景: find() 可以在任何类型的容器上使用，不论容器是否排序。这意味着它适用于无序容器（如 std::list、std::unordered_set）和有序容器（如 std::vector、std::set）。

binary_search() 函数:

工作原理: binary_search() 是一种二分搜索算法。它要求容器预先被排序。搜索开始于容器的中间元素，根据比较结果决定是继续在左侧子区间搜索还是右侧子区间搜索，这个过程递归进行，直到找到目标元素或确定元素不存在。

时间复杂度: 二分搜索的时间复杂度是 O(log n)，其中 n 是容器中元素的数量。这比线性搜索快得多，但前提是容器必须已经排序。

使用场景: binary_search() 仅适用于已排序的容器，如排序后的 std::vector、std::deque 或 std::array。它不适用于自然无序的容器，如 std::list 或 std::unordered_set。

# allocator

allocator 类是用于管理内存分配的。它是一种泛型编程的组成部分，主要用于容器类，如 vector、list 等，来分配和管理它们的内存。

allocator 的作用主要包括：

内存分配与回收：allocator 提供了分配和回收对象内存的方法。例如，allocate 方法用于分配内存，而 deallocate 用于释放内存。

对象构造与析构：除了管理内存，allocator 还可以在分配的内存上构造对象（使用 construct 方法）和析构对象（使用 destroy 方法）。

类型独立：由于 allocator 是模板化的，它可以用于任何类型的对象，这使得 STL 容器可以存储任何类型的元素。

性能优化：有些 allocator 实现可能提供优于默认内存分配器的性能。比如，它们可能有特殊的策略来减少内存碎片或提高内存分配效率。

应用场景举例：假设你正在使用一个 std::vector<int>，这个向量在内部会使用 allocator 来分配存储整数的内存空间。当向量需要增长时，allocator 会分配更大的内存区域，并帮助将现有元素移到新的内存位置。

简而言之，allocator 在 STL 中扮演着内存管理者的角色，确保容器能够高效地分配和管理内存。

# map & unoredered_map

C++ 标准模板库（STL）中的 std::map 通常是基于平衡二叉搜索树实现的，最常见的是红黑树。
红黑树是一种自平衡的二叉搜索树，它通过在树的节点中维护额外的信息（颜色标记为红或黑）来确保树保持平衡。
这种平衡性质确保了 std::map 的主要操作（如插入、删除和查找）的时间复杂度保持在 O(log n)，其中 n 是树中元素的数量。

## [红黑树]（https://www.cnblogs.com/crazymakercircle/p/16320430.html）

### B 树(便于查找 log(n))

二叉查找树（BST）具备以下特性：

- 左子树上所有结点的值均小于或等于它的根结点的值。
- 右子树上所有结点的值均大于或等于它的根结点的值。
- 左、右子树也分别为二叉排序树。

如果bst 树的节点正好从大到小的插入，此时树的结构也类似于链表结构，这时候的查询或写入耗时与链表相同 o(n)。

为了避免这种特殊的情况发生，引入了平衡二叉树（AVL）和红黑树（red-black tree）。

AVL 、rbt 都是通过本身的建树原则来控制树的层数和节点位置

### AVL

AVL树的特性
AVL树本质上还是一棵二叉搜索树，它有以下特性：

特性1： 对于任何一颗子树的root根结点而言，它的左子树任何节点的key一定比root小，而右子树任何节点的key 一定比root大；

特性2：对于AVL树而言，其中任何子树仍然是AVL树；

特性3：每个节点的左右子节点的高度之差的绝对值最多为1；

特性1表明，AVL 继承于 BST , 所以:

1. AVL本身首先是一棵BST 二叉搜索树。
2. AVL带有平衡条件：每个结点的左右子树的高度之差的绝对值（平衡因子）最多为1。

在插入、删除树节点的时候，如果破坏了以上的原则，AVL树会自动进行调整使得以上三条原则仍然成立。

也就是说，AVL树，本质上是带了平衡功能的二叉查找树（二叉排序树，二叉搜索树）。

AVL平衡的调整过程

旋转之前，首先确定旋转支点（pivot）： 这个旋转支点就是失去平衡这部分树，在自平衡之后的根节点，

平衡的调整过程，需要根据pivot它来进行旋转。

我们在学习AVL树的旋转时，不要将失衡问题扩大到整个树来看，这样会扰乱你的思路，
我们只关注失衡子树的根结点 及它的子节点和孙子节点即可。

事实上，AVL树的旋转，我们权且叫“AVL旋转”是有规律可循的，因为只要聚焦到失衡子树，然后进行左旋、右旋即可。

很多人在左旋和右旋有时候弄不明白，
其实左旋就是逆时针转，右旋是顺时针转

既然AVL树可以保证二叉树的平衡，这就意味着AVL搜索的时候，它最坏情况的时间复杂度O(logn) ，要低于普通二叉树BST和链表的最坏情况O(n)。

那么HashMap直接使用AVL树来替换链表就好了，为什么选择用红黑树呢？

原因是：

由于AVL树必须保证左右子树平衡，Max(最大树高-最小树高) <= 1，

所以在插入的时候很容易出现不平衡的情况，一旦这样，就需要进行旋转以求达到平衡。

正是由于这种严格的平衡条件，导致AVL需要花大量时间在调整上，故AVL树一般使用场景在于查询场景， 而不是 增加删除 频繁的场景。

红黑树(rbt)做了什么优化呢？

红黑树(rbt)继承了AVL可自平衡的优点，
同时, 红黑树(rbt)在查询速率和平衡调整中寻找平衡，放宽了树的平衡条件，从而可以用于 增加删除 频繁的场景。

与AVL树相比，红黑树牺牲了部分平衡性，以换取插入/删除操作时较少的旋转操作，整体来说性能要优于AVL树。

### RBT

在红黑树中，节点被标记为红色和黑色两种颜色。

红黑树的原则有以下几点：

特性1：节点非黑即红

特性2：根节点一定是黑色

特性3：叶子节点（NIL）一定是黑色

特性4：每个红色节点的两个子节点都为黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点)

特性5：从任一节点到其每个叶子的所有路径，都包含相同数目的黑色节点。

红色属性 说明，红色节点的孩子，一定是黑色。 但是，RBTree 黑色节点的孩子，可以是红色，也可以是黑色，具体如下图。

叶子属性 说明， 叶子节点可以是空nil ，AVL的叶子节点不是空的，具体如下图。

基于上面的原则，我们一般在插入红黑树节点的时候，会将这个节点设置为红色，

原因参照最后一条原则： 红色破坏原则的可能性最小，如果是黑色, 很可能导致这条支路的黑色节点比其它支路的要多1，破坏了平衡。

记忆要点：
可以按照括号里边的分类，记住 红黑树的几个原则：

（颜色属性）性质1：节点非黑即红

（根属性）性质2：根节点一定是黑色

（叶子属性）性质3：叶子节点（NIL）一定是黑色

（红色属性）性质4：每个红色节点的两个子节点，都为黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点)

（黑色属性）性质5：从任一节点到其每个叶子的所有路径，都包含相同数目的黑色节点。

黑色属性，可以理解为平衡特征， 如果满足不了平衡特征，就要进行平衡操作。

空间换时间,
RBT有点属于一种空间换时间类型的优化，

在avl的节点上，增加了 颜色属性的 数据，相当于 增加了空间的消耗。 通过颜色属性的增加， 换取，后面平衡操作的次数 减少。

rbt 的 左子树和右子树的黑节点的层数是相等的

红黑树的平衡条件，不是以整体的高度来约束的，而是以黑色 节点的 高度，来约束的。

所以称红黑树这种平衡为黑色完美平衡。

RBT面试题：
问：有了二叉搜索树，为什么还需要平衡二叉树？
二叉搜索树容易退化成一条链

这时，查找的时间复杂度从O ( log n）也将退化成O ( N )

引入对左右子树高度差有限制的平衡二叉树 AVL，保证查找操作的最坏时间复杂度也为O ( log n）

问：有了平衡二叉树，为什么还需要红黑树？
AVL的左右子树高度差不能超过1，每次进行插入/删除操作时，几乎都需要通过旋转操作保持平衡

在频繁进行插入/删除的场景中，频繁的旋转操作使得AVL的性能大打折扣

红黑树通过牺牲严格的平衡，换取插入/删除时少量的旋转操作，

整体性能优于AVL

红黑树插入时的不平衡，不超过两次旋转就可以解决；删除时的不平衡，不超过三次旋转就能解决

红黑树的红黑规则，保证最坏的情况下，也能在O ( log n）时间内完成查找操作。

问：红黑树那几个原则，你还记得么？
可以按照括号里边的分类，记住 红黑树的几个原则：

（颜色属性）节点非黑即红

（根属性）根节点一定是黑色

（叶子属性）叶子节点（NIL）一定是黑色

（红色属性）每个红色节点的两个子节点，都为黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点)

（黑色属性）从任一节点到其每个叶子的所有路径，都包含相同数目的黑色节点。

问：红黑树写入操作 ，是如何找到它的父节点的
红黑树的插入操作：
首先是找到一个合适的插入点，就是找到插入节点的父节点，

由于红黑树 它又满足BST二叉查找树的 有序特性，这个找父节点的操作和二叉查找树是完全一致的。

二叉查找树，左子节点小于当前节点，右子节点大于当前节点，

然后每一次向下查找一层就可以排除掉一半的数据，查找的效率在log(N)

最终查找到nil节点或者 key一样的节点。

如果最终查找到 key一样的节点，进行更新操作。这个TreeNode.key 与当前 put.key 完全一致。这就不需要插入，替换value就可以了，父节点就是当前节点的父节点

如果最终查找到nil节点，进行插入操作。nil节点的父节点，就是当前节点的父节点，把插入的节点替换nil节点。然后进行红黑树的 平衡处理。

问：红黑树的有那些内部操作
变色

把一个红色的节点变成黑色，或者把一个黑色的节点变成红色，就是对这个节点的变色。

旋转

与平衡二叉树的旋转操作类似。

红黑树与AVL树区别
1、调整平衡的实现机制不同

红黑树根据路径上黑色节点数目一致，来确定是否失衡，如果失衡，就通过变色和旋转来恢复

AVL根据树的平衡因子(所有节点的左右子树高度差的绝对值不超过1)，来确定是否失衡，如果失衡，就通过旋转来恢复

2、红黑树的插入效率更高

红黑树是用非严格的平衡来换取增删节点时候旋转次数的降低，任何不平衡都会在三次旋转之内解决，

红黑树并不追求“完全平衡”，它只要求部分地达到平衡要求，降低了对旋转的要求，从而提高了性能

而AVL是严格平衡树(高度平衡的二叉搜索树)，因此在增加或者删除节点的时候，根据不同情况，旋转的次数比红黑树要多。

所以红黑树的插入效率更高

3、红黑树统计性能比AVL树更高

红黑树能够以O(log n) 的时间复杂度进行查询、插入、删除操作。

AVL树查找、插入和删除在平均和最坏情况下都是O(log n)。

红黑树的算法时间复杂度和AVL相同，但统计性能比AVL树更高，

4、适用性：AVL查找效率高

如果你的应用中，查询的次数远远大于插入和删除，那么选择AVL树，如果查询和插入删除次数几乎差不多，应选择红黑树。

即，有时仅为了排序（建立-遍历-删除），不查找或查找次数很少，R-B树合算一些。

## std::unordered_map和std::map

std::unordered_map和std::map是C++标准库中的两种关联容器，它们都存储键值对并允许基于键的查找。但是，它们在内部实现、性能以及元素排序方面存在显著的区别。

内部实现：
std::map通常基于红黑树实现，红黑树是一种自平衡的二叉搜索树。这使得std::map的元素始终保持排序状态。
std::unordered_map基于哈希表实现。它使用哈希函数将键映射到桶中，然后在这些桶中存储相应的值。

元素排序：
std::map中的元素总是按键进行排序。这是因为红黑树保持了元素的有序性。
std::unordered_map中的元素不保证任何特定的顺序。元素的存储完全取决于哈希函数和桶的分配。

性能：
对于插入、删除和查找操作，std::unordered_map的平均时间复杂度通常为O(1)，这是因为它使用了哈希表。但是，在最坏的情况下（例如，当所有键都映射到同一个桶时），性能可能会降低到O(n)。
std::map的插入、删除和查找操作的时间复杂度为O(log n)，这是因为它基于红黑树实现。

空间占用：
由于std::unordered_map需要存储哈希表和额外的桶信息，它通常比std::map占用更多的空间。
std::map的空间占用相对较小，但由于其树结构，它可能需要更多的内存来存储节点间的指针。


在选择使用std::map还是std::unordered_map时，应根据你的具体需求进行权衡。如果你需要有序的元素或者可以接受对数时间复杂度的操作，那么std::map可能是一个更好的选择。如果你需要更高的平均性能并且不关心元素的顺序，那么std::unordered_map可能更适合你。

所以使用时map的key需要定义operator<。而unordered_map需要定义hash_value函数并且重载operator==。但是很多系统内置的数据类型都自带这些。

unordered_map的哈希函数如何自定义?

它必须是一个结构体或者类，其中包含一个重载的 operator()，这个操作符接受一个键类型的参数，并返回一个 size_t 类型的哈希值。

可以实现一个function 传入，也可以实现在 namespace std 中，使用全特化。

```cpp

// 自定义哈希函数
struct MyHashFunction {
    size_t operator()(const MyKeyType& key) const {
        // 计算并返回key的哈希值
        // 这里是一个示例，实际上应该根据key的实际结构来设计哈希算法
        return std::hash<int>()(key.id) ^ std::hash<std::string>()(key.name);
    }
};
```

## multimap
（1）对于 multimap，因为其具有自排序性质，可使用STL算法提供的 equal_range 接口，该接口使用二分法查找，返回一个 pair结构 保存查找元素的边界迭代器，pair中first指向找到的首个元素的迭代器，pair中second指向找到的最后一个元素下一个位置的迭代器，若未找到则second指向容器的end迭代器。

而对于 unordered_multimap，虽然它是一个无序容器，但因为可重复键，其元素会以键作为桶结构中桶的分类，向 unordered_multimap 添加重复键的元素时，会放在同一个键的桶内，本质上是对重复键进行了桶排序，所以也可以使用 equal_range 获取找到查找的边界迭代器。

### equal_range， lower_bound， upper_bound（前开后闭 [lower,upper) ）

lower_bound() 和 upper_bound() 是 C++ STL 中用于在已排序的范围内进行二分搜索的两个函数。它们的作用是找到一个范围内不小于（或不大于）某个给定值的第一个元素的位置。这两个函数通常用于有序序列，尤其是在处理有重复元素时非常有用。

lower_bound():
返回一个迭代器，指向在不破坏顺序的情况下，可以插入给定值的第一个位置，而不让任何原有的元素小于给定值。
如果序列中存在与给定值相等的元素，lower_bound() 会返回指向这些元素中第一个的迭代器。
如果所有元素都小于给定值，则返回指向序列尾部的迭代器。
upper_bound():
返回一个迭代器，指向在不破坏顺序的情况下，可以插入给定值的最后一个位置，而不让任何原有的元素小于或等于给定值。
如果序列中存在与给定值相等的元素，upper_bound() 会返回指向这些元素中最后一个之后的迭代器。
如果所有元素都小于或等于给定值，则返回指向序列尾部的迭代器。

# list

链表是一种物理存储单元上非连续、非顺序的存储结构，数据元素的逻辑顺序是通过链表中的指针链接次序实现的。链表由一系列结点（链表中每一个元素称为结点）组成，结点可以在运行时动态生成。

每个结点包括两个部分：一个是存储数据元素的数据域，另一个是存储下一个结点地址的指针域。

 相较于vector的连续线性空间，list就显得负责许多，它的好处是每次插入或者删除一个元素，就是配置或者释放一个元素的空间。因此，list对于空间的运用有绝对的精准，一点也不浪费。而且，对于任何位置的元素插入或元素的移除，list永远是常数时间。 List和vector是两个最常被使用的容器。 List容器是一个双向链表。

List容器不能像vector一样以普通指针作为迭代器，因为其节点不能保证在同一块连续的内存空间上。List迭代器必须有能力指向list的节点，并有能力进行正确的递增、递减、取值、成员存取操作。所谓”list正确的递增，递减、取值、成员取用”是指，递增时指向下一个节点，递减时指向上一个节点，取值时取的是节点的数据值，成员取用时取的是节点的成员。 由于list是一个双向链表，迭代器必须能够具备前移、后移的能力，所以list容器提供的是Bidirectional Iterators. List有一个重要的性质，插入操作和删除操作都不会造成原有list迭代器的失效。这在vector是不成立的，因为vector的插入操作可能造成记忆体重新配置，导致原有的迭代器全部失效，甚至List元素的删除，也只有被删除的那个元素的迭代器失效，其他迭代器不受任何影响。 list容器不仅是一个双向链表，而且还是一个循环的双向链表。

怎么判断一个迭代器是随机访问迭代器还是双向迭代器

简单判断：迭代器+1，如果成功，就是随机访问迭代器，否就是双向迭代器。

std::forward_list 是一种单向链表，即只允许沿一个方向遍历，
forward_list 的用法与 list 很像，但只能沿一个方向移动迭代器，且插入元素时只能使用函数push_front( )，而不能使用 push_back( )。只能对迭代器使用运算符++，而不能使用--。

forward_list 的优点在于，它是一种单向链表，占用的内存比 list 稍少，因为只需指向下一个元素，而无需指向前一个元素。

std::sort和list成员函数sort有什么区别吗？

二师兄：std::sort是STL算法的一部分。它排序的容器需要有随机访问迭代器，所以只能支持vector和deque。list成员函数sort用于list排序，时间复杂度是O(N*logN)。

list在pop_front/pop_back的时候需要注意哪些问题？

二师兄：需要判断list的size()不能为0，如果list为空，pop_front/pop_back会导致coredump。

面试官：你知道list的成员函数insert和forward_list的成员函数的insert_after有什么区别？

二师兄：两者都可以向特定位置添加元素。不同的是insert把元素插入到当前迭代器前，而insert_after把元素插入到当前迭代器后。

# vector、list、deque 的选择原则

vector可以随机存储元素（即可以通过公式直接计算出元素地址，而不需要挨个查找），但在非尾部插入删除数据时，效率很低，适合对象简单，对象数量变化不大，随机访问频繁。除非必要，我们尽可能选择使用vector而非deque，因为deque的迭代器比vector迭代器复杂很多。

list不支持随机存储，适用于对象大，对象数量变化频繁，插入和删除频繁，比如写多读少的场景。

需要从首尾两端进行插入或删除操作的时候需要选择deque。

也即：

需要对数据高效的随机访问（存取），而不在乎插入和删除的效率，采用vector。数据存储之后经常进行查询，只会追加数据（序列化的 buffer）

需要大量插入、删除数据，而不关心随机访问数据，采用list。

需要随机访问数据，而且关心前后增删数据的能力，采用deque。（pending request request）

对数据中间的增删操作比较多，采用list，建议在排序的基础上，批量进行增删可以对运行效率提供最大的保证。

# deque

双端数组，可以对头端进行插入删除的操作。

deque和vector的区别：

- vector对于头部的插入删除效率低，数据量越大，效率越低。
- deque相对而言，对头部的插入删除速度比vector快。
- vector访问元素时的速度会比deque快，这和两者的内部实现有关。

deque内部工作原理：

deque内部有一个中控器，维护每一段缓冲区中的内容，缓冲区中存放真实数据，中控器维护的是每个缓冲区的地址，使得使用deque的时候像一片连续的内存空间(实际不一定是连续的)。访问元素的速度没有vector快，一个缓冲区访问完了，要通过地址找到下一个缓冲区来进行访问。

deque容器的迭代器也是支持随机访问的。

# vector

vector的一些主要特点和应用场景：

动态大小：与传统的数组不同，vector可以根据需要动态地扩展或缩减大小。这意味着你不需要事先知道数据的数量。
随机访问：就像数组一样，vector支持随机访问，这意味着你可以通过索引直接访问任何元素，访问时间是常数时间复杂度（O(1)）。

内存管理：vector在内部管理其存储的内存。当元素被添加到vector中，并且当前分配的内存不足以容纳它们时，它会自动重新分配更多的内存。

灵活性：你可以在vector的末尾添加或删除元素，而且效率很高。但在中间或开始位置插入或删除元素可能会比较慢，因为这可能需要移动现有的元素。

应用场景

动态数据集合：当你需要一个可以根据数据量动态调整大小的数组时，vector是一个很好的选择。例如，处理用户输入的数据集，其中输入数量事先未知。

需要快速访问的数据：由于vector支持随机访问，它非常适合于需要频繁读取元素的情况，比如查找或排序算法中。

性能敏感的应用：由于其元素紧密排列在连续的内存块中，vector通常提供高效的内存访问性能，适合用于性能敏感的应用。

## vector深浅拷贝问题
首先来看看以下代码:
```cpp
vector<vector<int>> vv(3,vector<int>(5));
```
这是一个二维数组,初始化为三行五列
```cpp
vector<vector<int>> vv(3,vector<int>(5));
vector<vector<int>> x(vv);
```
这是在拷贝构造类对象 x

自我实现的拷贝构造使用的是 memcpy:
```cpp
Vector(const Vector<T>& v)
{
	assert(v._start && v._finish && v._endofsto);
	_start = new T[v.capacity()];//给size或capacity都可以
	memcpy(_start, v._start, sizeof(T) * v.size());
}
```
然而memcpy是逐个字节拷贝. 当数组是一维时,用memcpy没有问题，但是当数组是二维数组时,会出错!

解决方法

由于这种深浅拷贝问题是因为memcpy
导致的,所以这里不能使用memcpy
只需要老实的使用一个for循环就能解决:
```cpp
Vector(const Vector<T>& v)
{
	assert(v._start && v._finish && v._endofsto);
	_start = new T[v.capacity()];//给size或capacity都可以
	//memcpy(_start, v._start, sizeof(T) * v.size()); //使用memcpy时,数组是二维数组会发生问题
	for (size_t i = 0; i < size(); i++)
	{
		_start[i] = v._start[i];
		_finish = _start + v.size();
	}
	_endofsto = _start + v.capacity();
}
```

## resize()和reserve()区别

void resize(size_type n, value_type val = value_type());

- 如果n<当前容器的size，则将元素减少到前n个，移除多余的元素(并销毁）
- 如果n>当前容器的size，则在容器中追加元素，如果val指定了，则追加的元素为val的拷贝，否则，默认初始化
- 如果n>当前容器容量，内存会自动重新分配


void reserve(size_type n)

- 如果n>容器的当前capacity，该函数会使得容器重新分配内存使capacity达到n
- 任何其他情况，该函数调用不会导致内存重新分配，并且容器的capacity不会改变
- 该函数不会影响向量的size而且不会改变任何元素


1、vector的reserve增加了vector的capacity，但是它的size没有改变！而resize改变了vector的capacity同时也增加了它的size！

2、reserve是容器预留空间，但在空间内不真正创建元素对象，所以在没有添加新的对象之前，不能引用容器内的元素。加入新的元素时，要调用push_back()/insert()函数。

3、resize是改变容器的大小，且在创建对象，因此，调用这个函数之后，就可以引用容器内的对象了，因此当加入新的元素时，用operator[]操作符，或者用迭代器来引用元素对象。此时再调用push_back()函数，是加在这个新的空间后面的。

4、两个函数的参数形式也有区别的，reserve函数之后一个参数，即需要预留的容器的空间；resize函数可以有两个参数，第一个参数是容器新的大小，第二个参数是要加入容器中的新元素，如果这个参数被省略，那么就调用元素对象的默认构造函数。


## vector的.at()和[ ]

最主要的区别就是.at()会额外检查访问是否越界，如果越界，会抛出exception，所以使用.at()时程序运行速度较慢。

二者优点

一般来说用[]效率更高，尤其是需要对索引值进行复杂的计算或者单纯不需要检查是否越界时。
更好的做法是默认用.at()，这样代码尽管很慢但不会产生bug；[]更适合对程序效率要求比较高的场景。

[]缺点

索引值越界时程序不会报错，但会一路莽下去，在向量非空的情况下，即使下标越界，也有可能对应的内存是可读写的，至于读到的是什么内容，或者写到什么地方，就是随机事件了。

由于[]不做边界检查，哪怕越界了也会返回一个引用，当然这个引用是错误的引用，如何不小心调用了这个引用对象的方法，会直接导致应用退出。

处理.at()越界访问

我们用try可以catch out_of_bound exception:

```cpp
try {
	cout << "Out of range element value: "
		 << v.at(container_size + 10) << "/n.";
 } catch(const out_of_range &e) {
	cout << "Ooops, out of range access detected: "
		 << e.what() << "/n."
 }
```

## push_back和emplace_back有什么区别？

vector 的 push_back 和 emplace_back 函数都是用来在 vector 的末尾添加新元素的，但它们之间有几个关键的区别：

构造方式：
push_back 函数会复制或移动已经构造好的对象到 vector 的末尾。
emplace_back 函数则是直接在 vector 的末尾构造新元素，它接受的是构造函数的参数，而不是对象本身。

性能：
使用 push_back 时，如果传入的是一个临时对象，它首先会被构造，然后再被复制或移动到 vector 中（C++11起，会尝试使用移动构造减少开销）。
emplace_back 则可以避免这些额外的复制或移动操作，因为它直接在容器的内存中构造对象，从而可能提供更好的性能。

例子：
使用 push_back 添加一个复杂对象时：myVector.push_back(MyClass(a, b, c)); 这里 a, b, c 是传递给 MyClass 构造函数的参数，首先在外部构造一个临时的 MyClass 对象，然后将其添加到 vector。
使用 emplace_back 相同的操作：myVector.emplace_back(a, b, c); 这里直接将参数 a, b, c 传递给 emplace_back，在 vector 的内存空间中直接构造对象，无需临时对象。

# 迭代器失效

## 一、序列式容器(数组式容器)

对于序列式容器(如vector,deque)，序列式容器就是数组式容器，删除当前的iterator会使后面所有元素的iterator都失效。这是因为vetor,deque使用了连续分配的内存，删除一个元素导致后面所有的元素会向前移动一个位置。所以不能使用erase(iter++)的方式，还好erase方法可以返回下一个有效的iterator。
```cpp
for (iter = cont.begin(); iter != cont.end();)
{
   (*it)->doSomething();
   if (shouldDelete(*iter))
      iter = cont.erase(iter);  //erase删除元素，返回下一个迭代器
   else
      ++iter;
}
```
## 二、关联式容器

对于关联容器(如map, set,multimap,multiset)，删除当前的iterator，仅仅会使当前的iterator失效，只要在erase时，递增当前iterator即可。这是因为map之类的容器，使用了红黑树来实现，插入、删除一个结点不会对其他结点造成影响。erase迭代器只是被删元素的迭代器失效，但是返回值为void，所以要采用erase(iter++)的方式删除迭代器。

## 链表式容器

对于链表式容器(如list)，删除当前的iterator，仅仅会使当前的iterator失效，这是因为list之类的容器，使用了链表来实现，插入、删除一个结点不会对其他结点造成影响。只要在erase时，递增当前iterator即可，并且erase方法可以返回下一个有效的iterator。

方式一:递增当前iterator

同 map `erase(iter++)`

方式二:通过erase获得下一个有效的iterator

同 vector： `iter = erase(iter)`


## 四、总结

迭代器失效分三种情况考虑，也是分三种数据结构考虑，分别为数组型，链表型，树型数据结构。

数组型数据结构：该数据结构的元素是分配在连续的内存中，insert和erase操作，都会使得删除点和插入点之后的元素挪位置，所以，插入点和删除掉之后的迭代器全部失效，也就是说insert(*iter)(或erase(*iter))，然后在iter++，是没有意义的。解决方法：erase(*iter)的返回值是下一个有效迭代器的值。 iter =cont.erase(iter);

链表型数据结构：对于list型的数据结构，使用了不连续分配的内存，删除运算使指向删除位置的迭代器失效，但是不会失效其他迭代器.解决办法两种，erase(*iter)会返回下一个有效迭代器的值，或者erase(iter++).

树形数据结构： 使用红黑树来存储数据，插入不会使得任何迭代器失效；删除运算使指向删除位置的迭代器失效，但是不会失效其他迭代器.erase迭代器只是被删元素的迭代器失效，但是返回值为void，所以要采用erase(iter++)的方式删除迭代器。

注意：经过erase(iter)之后的迭代器完全失效，该迭代器iter不能参与任何运算，包括iter++,*ite
