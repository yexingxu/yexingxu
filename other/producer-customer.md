<!--
 * @Description:
 * @Version: 2.0
 * @Author: chen, hua
 * @Date: 2023-11-07 11:13:30
 * @LastEditors: chen, hua
 * @LastEditTime: 2023-11-08 11:40:34
-->
# 生产者消费者模式
生产者消费者问题（Producer-consumer problem），也称有限缓冲问题（Bounded-buffer problem），是一个多进程同步问题的经典案例。该问题描述了共享固定大小缓冲区的两个进程——即所谓的“生产者”和“消费者”——在实际运行时会发生的问题。生产者的主要作用是生成一定量的数据放到缓冲区中，然后重复此过程。与此同时，消费者也在缓冲区消耗这些数据。该问题的关键就是要**保证生产者不会在缓冲区满时加入数据，消费者也不会在缓冲区中空时消耗数据**。

一般根据生产者和消费者的数量，进行组合，可以分为下面几种，针对不同的情况，会有对应的优化策略：

- **SPSC（Single Producer & Single Consumer）**，对于单生产者单消费者，只有同步没用互斥，只用保证缓冲区满的时候，生产者不会继续向缓冲区放数据，缓冲区空的时候，消费者不会继续从缓冲区取数据，而不存在同时有两个生产者使用缓冲区资源，造成数据不一致的状态。

- **MPSC（Multiple Producer & Simple Consumer）**，对于多生产者单消费者来说，多生产者之间具有互斥关系，需要加锁。

- **SPMC（Single Producer & Multiple Consumer）**，类似MPMC模式。

- **MPMC（Multiple Producer & Multiple Consumer）**，对于多生产者多消费者问题，是一个同步+互斥问题，不仅需要生产者和消费者之间的同步协作，还需要实现对缓冲区资源的互斥访问。

## [ring buffer](https://zhuanlan.zhihu.com/p/534098236)

ring buffer 称作环形缓冲区，也称作环形队列（circular queue），是一种用于表示一个固定尺寸、头尾相连的缓冲区的数据结构，适合缓存数据流。在任务间的通信、串口数据收发、log缓存、网卡处理网络数据包、音频/视频流处理中均有环形缓冲区（ring buffer） 的应用。

环形缓冲区的一些使用特点如下：

- 当一个数据元素被读取出后，其余数据元素不需要移动其存储位置;
- 适合于事先明确了缓冲区的最大容量的情形。缓冲区的容量（长度）一般固定，可以用一个静态数组来充当缓冲区，无需重复申请内存；
- 如果缓冲区的大小需要经常调整，就不适合用环形缓冲区，因为在扩展缓冲区大小时，需要搬移其中的数据，这种场合使用链表更加合适；
- 因为缓冲区成头尾相连的环形，写操作可能会覆盖未及时读取的数据，有的场景允许这种情况发生，有的场景又严格限制这种情况发生。选择何种策略和具体应用场景相关。

由于计算机内存是线性地址空间，因此环形缓冲区（ring buffer）需要特别的算法设计才可以从逻辑上实现。

实现环形缓冲区（ring buffer）需要注意到几个问题点：

- 在缓冲区满的时候写数据，有两种策略可以使用：第一覆盖掉老数据；第二抛出异常；
- 读数据时，一定要读出缓冲区中最老的数据（缓冲区中数据满足FIFO特性）；
- 怎样来判断缓冲区是满的；
- 如何实现一个线性地址空间的循环读写。

缓冲区变满在环形缓冲区（ring buffer）中会实际发生，一般会有两种处理策略，第一覆盖掉老数据；第二抛出“异常”。这两种策略该如何选择要结合具体的应用场景。如音/视频流中，丢掉一些数据不要紧，可以选择第一种策略；在任务间通信的时候，要严格保证数据正确传输，这个时候就要选择第二种策略。

### false sharing 伪共享

#### Cache Memory
我们都知道 CPU 和主内存之间的运算速度是差异巨大的，在现今的 SMP（Symmetric Multiprocessor）System 中，会在 CPU 和主存间设置三级高速缓存，L1、L2 和 L3，读取顺序由先到后。实际上 Cache 的设计是经历过变更的，Intel和 AMD 的实现细节都不尽相同，本文你可以简单理解为，L1 Cache分为指令缓存和数据缓存两种，L2 Cache只存储数据，L1 和 L2 都是每个核心都有，而 L3 被多核共享。

#### MESI
那么问题来了，多核CPU的情况下有多个 L1 和 L2 缓存，如何保证缓存内部数据的一致,不让系统数据混乱。这里就引出了一个一致性的协议MESI。

MESI规定了一个cache line存在四种状态：Modified、Exclusive、Shared 和Invalid，这有点像状态机的转换，理清全部的状态较复杂，我们关注简单的：

- Modified：该缓存行只被缓存在该CPU的缓存中，并且是被修改过的，即与主存中的数据不一致，该缓存行中的内存需要在未来的某个时间点（允许其它CPU读取请主存中相应内存之前）写回主存。当被写回主存之后，该缓存行的状态会变成Exclusive状态。
- Exclusive：该缓存行只被缓存在该CPU的缓存中，它是未被修改过的，与主存中数据一致。该状态可以在任何时刻当有其它CPU读取该内存时变成Shared状态。同样地，当CPU修改该缓存行中内容时，该状态可以变成Modified状态。
- Shared：该状态意味着该缓存行可能被多个CPU缓存，并且各个缓存中的数据与主存数据一致，当有一个CPU修改该缓存行中，其它CPU中该缓存行可以被作废。
- Invalid：该缓存是无效的（可能有其它CPU修改了该缓存行）。

#### 缓存行Cache Line 是啥
Cache Line :顾名思义叫做缓存行

缓存行越大，局部空间效率越高,读取时间越慢!

缓存行越小，局部空间效率越低，读取时间越快!

总所周知，计算机将数据从主存读入Cache时，是把要读取数据附近的一部分数据都读取进来
这样一次读取的一组数据就叫做CacheLine，每一级缓存中都能放很多的CacheLine

#### CacheLine对齐
多线程会有上面的伪共享问题，但如果x,和y分别在不同的cacheLine中进行修改读取，双方就不会一直发生同步了，因为另一个线程根本就没有这个数据!

如果让两个数据处于不同的CacheLine呢？方法就是Cache Line对齐

在一般的x86环境下一个CacheLine是64字节，也就是8个Long，我们可以把x定义为Long，并同时定义7个没有用的Long变量，这样这8个数就在同一个CacheLine中
之后再定义y，y自然也就在下一个CacheLine中

这就叫CacheLine对齐，这样两线程就不会出现伪共享的现象了